professor of June why in your written testimony you discuss how companies use automated video interviewing that permits the employer to evaluate factors that are not job-related in the interviewing process last year in the Science Space and Technology Committee joy boo Ballymena knee it was the founder of the [Music] algorithmic Justice League testified on some of these issues and they discuss their experience with facial analysis software failing to detect their dark skin until they put on a white mask which uncovered both skin type and gender bias in the AI services from companies like Microsoft IBM Amazon so professor what characteristic can employers evaluate when using automated video interviewing and to individuals typically know these factors being evaluated as they interview thank you for your question cherubim amici so the one of the bigger problems that automated video interviewing is that oftentimes the job applicants don't actually know that they will be evaluated based on their video they just think that they are sending in a video that will then be viewed by humans but actually that video is actually being put through algorithms that are evaluating both the facial expressions tone of voice even word choice and the problem with that of course is that if you look at how the training of the algorithm is done oftentimes the training is using a very limited pool of applicants so it could be all white male applicants and in which case women who have different tones of voices or even people who are from other cultures and therefore have different facial expressions can actually be disadvantaged because then the air responses can be misinterpreted by the algorithm thank you on both on this committee and on the Science Committee we have a lot of conversations about the importance of diversifying this steam work for us and I I think that that is one step in solving this problem because obviously is designing the algorithm it makes a difference mr. Romer Friedman in your testimony you said that job advertisements are often targeted based on categories that are not job-related or proxies and you described how individuals may be excluded from seeing job ads thank you for the actual visual representation do you consider excluding an individual from seeing a job ad because their experience exceeds a maximum number of years or because they attended a women's college for example would those be examples of targeting based on proxies absolutely cherubim michi these are these are the kinds of things that without the digital procedures and processes could be illegal we see this a lot in the economy for older workers they're excluded simply because they have too many years of experience or they graduated from college a number of years ago but we're seeing the same thing accelerated and exacerbated in the digital space and that's a problem we think that it clearly violates the law it not only has a disparate impact we think you can infer intentional discrimination from these kinds of clear proxies how could Congress best make sure that the employers are not using proxies to discriminate based on sex age religion and other categories as I've recommended and my testimony Congress could explicitly say that if a job category or if a category for targeting someone or evaluating someone is not directly related to the to the job or the opportunity it simply is banned it would be an unlawful practice in the same way that it's just strictly unlawful regardless of the intent to advertise a job that states a preference based on age or race or gender thank you Miss yang your former chair the Equal Employment Opportunity Commission what additional resources could Congress provide to the EEOC the Commission on civil rights in the office of Federal contract compliance programs to adequately address the problems that were described today with algorithmic bias and digital discrimination in hiring Thank You chair Ponte meats you for that question the government plays a particularly important role in rooting out hiring discrimination because individuals typically don't know they weren't hired so the EEOC made it a priority to look at recruiting and hiring discrimination and the agency has authority to open charges on their own investigation even where an individual may not have enough information so right now under our current law the federal government plays an incredibly important role in investigating concerns about hiring screens and the agencies need more resources they need to be able to hire computer scientists and data scientists who understand how these systems work we had initially started a task force over four years ago back when I was at the EEOC we had professor Jun wah testify and help us learn about these issues but we didn't have the capacity on staff to really fully understand how to evaluate these systems understand how the uniform guidelines really need to be updated and having that technical know-how within the agency would be incredibly valuable thank you so much I yield back and recognize