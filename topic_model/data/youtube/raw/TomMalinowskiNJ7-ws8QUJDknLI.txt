and thanks to noah pransky there we now know how q anon works and we've seen how it can have negative impacts on everything from our health care to our elections and now lawmakers are trying to do something about it by considering amending the way that section 230 of the communications decency act actually works representative tom malinowski he's a democrat from new jersey and he introduced legislation in 2020 that would remove liability immunity for a platform based on certain criteria according to the hill he has since discussed legislation with the biden administration that companies would be held legally liable if they promote content using algorithms designed to increase profits and audience metrics if that content then leads to violence now when asked about social media companies moderating their own content he said quote social media companies have been playing a whack-a-mole trying to take down q on conspiracies and other extremist content but they aren't changing the design of a social network that is building to amplify extremism but he's also found himself on the receiving end of digital extremism according to the new york times supporters of cuban on began to target him after he led a bipartisan resolution condemning the movement in an ad falsely claiming that he worked to block a provision that would have expanded registration requirements for sex offenders and death threats as well as harassment then followed the whole thing really is complicated but it basically comes down to misinformation resulting in real world harm so we are bringing in the former assistant secretary of state and the current representative for new jersey's seventh district tom malinowski himself thank you so much for taking the time to join us here tom let's start with q anon now we've seen social media companies take action against the french group but what else actually needs to change so social media companies have taken action as as you said by taking down individual posts by taking down groups that are dedicated to q and on and as you suggested i call that a game of whack-a-mole because there are billions of people on social media and billions of posts every single day and you take down one conspiracy and some other conspiracy arises in its place the problem i think is that the networks themselves these social media platforms themselves are designed to amplify these kinds of extreme content um and and the reason for this is that you know when you log on to facebook or instagram or watch videos on on youtube you're not getting what your friends post in chronological order there is an algorithm written by these companies that decides everything that we see and what they figured out is that if they feed us content that reinforces our pre-existing beliefs content that makes us angry content that makes us afraid of something that triggers those emotions we will spend more time on their platforms we'll click more ads we'll buy more stuff from the people who post those ads and they'll make more money um and so right now all the incentives are in favor of them actually amplifying uh theories like q anon and other extreme ideas not to take them down and so that's what's got to change and how do you educate also other members of congress about this now we've seen you know some of those meetings and those hearings talking about how social media is affecting all of uh all of this but we've also seen it seems like a lack of knowledge amongst your constituents and also amongst uh the individuals you work with sometimes yeah it's you know the easy thing to understand when we debate social media is what should you take down and what should you leave up like everybody understands there's something bad that was said on the internet should we take it down or not is that censorship or not so that's a debate that's very easy for members of congress to engage in it's a little bit more complicated to look under the hood and understand the engine that drives social media the engine that you don't see that determines the content that we see that decides what goes viral and what when what doesn't and so we've we've you know i've spent the last few months and others have tried to explain this to uh to my colleagues and you know what really was the best explainer it was what happened on capitol hill on january 6th when suddenly we were set upon by this map this mob of thousands of people who had been radicalized in the social media echo chamber to believe things that were not true and to do things that under normal circumstances normal people would never have dreamed of doing so since then i think there's greater awareness it's good that there's more awareness but it's also bad that it had to come to that point i also first like i want to talk about you and the threats that you received and the push for change how did that affect you personally it just made me more determined you know what happened was last year i uh i sponsored a resolution in in the house to condemn q anon really simple just to say this is bad and the key was i wanted to get republicans as well as democrats on board and we were successful only 17 members of the house voted against it overwhelmingly we came together but um while that was happening i was also running for re-election a really close race in new jersey and the republicans who were running against me ran an ad that basically played to the q anon conspiracy theory trying to link me to pedophilia and child sex trafficking and everybody said it was crazy and false but it didn't stop them from hammering that message itself put these things together and there was a so-called q-drop which is what what what what you call an actual post by the the q entity this mysterious figure supposedly behind q anon and that post basically said hey look this is the congressman who's leading the charge against us and at the same time he's linked to the conspiracy and how do we know well the republican party is telling us that and on that day i got a whole bunch of death threats from q anon supporters around the country i'm sorry you had to go through that but you know there's that old saying that if you have haters you must be doing something right can you also you know explain for our viewers how section 230 is currently set up and how it would change if your legislation was passed sure so section 230 was adopted in the early days of the internet before social media and the the idea was that if you if you own a website people then post stuff on your website you're not responsible for what they post your website is kind of like an old-fashioned community bulletin board where you know people you know tack a message on and all you are is the company that provides the bulletin board and so it says facebook uh google twitter they are not legally responsible for what you and i post on their websites the problem is that social media as we've been discussing it's evolved into this thing where it's not just a community bulletin board the companies decide what happens to our posts the companies decide what goes viral they decide how to amplify and promote that content and so what i'm saying is you actually you you are responsible for the consequences if you're writing these powerful algorithms that that cause this information to spread so what we are saying we're not eliminating section 230 i'm not trying to kill the internet what we're saying is that if you are using your algorithms to promote content that is later linked to an act of violence an act of terrorism a violent hate crime like what happened on capitol hill on january 6th then the victims can sue you and what that hopefully will induce his decisions by these companies to change how they design their networks so that they can protect themselves against lawsuits well tom malinowski thank you so much for taking the time here to join us on bclx and really dive in and explain this for our viewers thank you so much